---
layout: post
title: "Stop saying that AI is just a tool and it only matters how it is used"
slug: just-a-tool
tags:
- ai
- economy
- tools
- existence
- existentialism
- environment
- ml
- llms
description: "I'm tired of this phrase and this simple way of thinking about tools. This blog post is a wandering train of thought on the topic of what tools are and why it matters to be even slightly more mature in how we think about them."
---

I've been thinking constantly about the common and casual phrase I've heard so often, "AI is just a tool - it matters how you use it." This has been the rallying cry of tech-loving academics who no longer do their own research, tech bros who salivate over generative images of criminal depictions of people without their consent, and business-minded folks who actually don't care about AI but see this as an opportunity to rake in more and more money for themselves.

The phrase is deceptively simple and deceptively misleading. Yes, AI *is* a tool. And yes, it *is* important how we choose to use tools. "A car is just a tool, it matters how you drive it." Well... oil and gas is destroying the climate, seatbelts help save lives whether or not someone is a good driver, and since the invention of cars, American city design has become utterly unwalkable and unlivable.

So there is much more to tools than how we use them. And since I have seen this phrase used by award-winning, hihgly successful academics, I think that some who speak this phrase know what they are doing. Some people may not have interrogated what tools can do and the ethics of tool usage. But for people who know better, they use this phrase as a malicious dismissal of legitimate concern for what AI is doing to the world. They want to keep people quite with a childishly simple obliteration of everything that actually matters about tools.

The part of the phrase, "it's just a tool" is nonsense. Tools are massively impactful on our environment, law, policy, and what it means to be human. Believing that AI is "just a tool" is naive at best and dismissive at worse because nothing about tools is "just" anything. They are highly complex parts of life and culture.

The last part of the phrase, "it matters how you use it" is also deceptively misleading and overly simplistic. Oh really? The entirety of all ethics involved in modern technological ecosystems and infrastructures rests solely on how a singular person chooses to use something?

The reason people say something like this is because it immediately invites solutionism. "It matters how you use it" is an intellectual half-gesture. The audience who hears that phrase will sagely agree, "ah, of course, in my wisdom I know how to use things well. And this means that is all there is to it!" It turns people into fools, thinking they are wizards. "It matters how you use it" is then a glaringly simple, solveable problem space: well, some people just don't *know*. "All we need to do is teach people how to swing a hammer, and then hammers are ethically good!"

Even a hammer, made of wood and iron, requires trees to be cut down and earth to be mined up. A simple hammer requires laws to be written about fair treatment of workers, sustainability of our environments, and regulation about the sale and use of the hammer. "It matters how you use it," in regards to artificial intelligence ignores the reality that it also matters how AI is made, how AI is disseminated, the waste AI produces, the damage AI causes to economies and environments, and the overall impact that AI has on human life and culture.

"It matters how you use it" is something that an immature and self-absorbed young child would say, a child who has yet to reckon with the reality that they live in a society full of other people and other living organisms and participates in a system of entities that are all constantly fighting for fairness, dignity, and survival. Tools matter because of how they are made, what makes them, and how the world changes because of how we use them.

I loathe the phrase, "AI is just a tool, it matters how you use it."

## On tools and *being*
And tools use *us* by their design. This is Heidegger's Gestell ("en-framing"): the notion that technologies shape who we are because of their design and use. A hammer *isn't* just made of wood and iron, then. A hammer is a hammer because of what it does and who we *become* when we use it.

Tools, then, aren't "neutral" in any way.

My dissertation centers on this tension and builds on it: well, if tools aren't neutral - *then what?* In my dissertation, I focus on accessibility and tool design as an intervention, but the concepts, imperatives, and calls to action in my dissertation can be applied more broadly:

We must interrogate and reshape our technologies. We need to fight back against design that flattens our humanity at the benefit of efficiency and productivity. We need to question how our tools have created infrastructures and landscapes that are hostile to human existence. And of course:

We *must* interrogate how tools shape us, by their design.

Take the "chair:"

> [Anna Gyllenklev writes](https://www.linkedin.com/posts/anna-gyllenklev-752253174_naming-as-framing-a-chairs-logic-activity-7331612556618346497-uoId?utm_source=social_share_send&utm_medium=member_desktop_web&rcm=ACoAADDAwBkBOdoW11I9B5DHy57VfR5jIs33Kq0), 
> "Ever feel like your chair is bossing you around?
> “Sit still. Face forward. Behave.”

A chair orders you to sit and sit in a particular way, by its design.

Your being is *intended* through the tool: you are intended to sit still, face forward, and behave. Artificial intelligence works in exactly the same way. We might use these tools believing that "it's all in how you use them" - and yet, still, our tools are using us. Our being is, perhaps more now than it has ever been, intended to become *reliant* on our tooling. All tools do this, it isn't new.

But artificial intelligence, far more than any tool we've ever created, intends us not just to sit forward and behave, but to cease to think critically, to cease to imagine, and, most temptingly, to cease to feel struggle and pain.

## Knowing the difference between drudgery and meaningful struggle
The greatest selling point of automation has always been to remove drugery. And at the heart of drugery is struggle and pain. Artificial intelligence *equates* struggle to drudgery: all difficulty can and should be removed from work. Equating struggle to drudgery AI's ultimate deception: we can simply ask for art and it materializes before us. There is no struggle at all involved, thus the terrible labor of being an artist is removed!

And AI is not new, in this regard. The flattening of all pains into a total loss of pain has previously been the job of chemicals and theology. So AI is therefore more like an *opiate*, a drug, than anything else. Or perhaps, given the fervor of its modern supplicants, it is more like a religion.

But automation of everything numbs who we are. Total automation softens our ability to discern between struggle that makes and pain that takes. The discernment that comes from being able to know the difference between these two things is perhaps among the most important lessons learned in life: when should you fight for something and overcome and when are certain barriers themselves, by nature of their existence, fundamentally cruel?

How you answer these two questions should inform how you treat the use of AI:

> If it was possible: Should we climb a mountain, or flatten it? And should we climb a curb, or cut it?

Take the gym, for example: struggle against the pain of exercise is rewarding and uplifting. The weights don't have to be moved, lifting them isn't a required task of us. It would be nonsense to ask a robot to lift weights for us at the gym.

However, tools and technologies that improve how *we* lift weights are a recognition of our love of lifting. Newer, safer weight lifting machines, protections from dropped weights, stronger cables, mirrors in front of the dumbells, and so on. Many technologies exist to enhance our human love of struggle.

We cease to feel struggle when we use AI. We don't need to write our mothers a well-meaning email on her birthday, we don't need to make the case for our promotion to our bosses, we don't need to think through the hard parts of an algorithm we are writing, and, when it comes to art, we don't need to feel the pain of improving our craft. We simply prompt, and (optionally) we could choose to do the work of validating whatever it came up with. But of course, automating validation is just another thing that modern AI-dreamers dream of.

Artificial intelligence is the quintessential tool-as-a-drug. It operates with an [economy of infinity](https://www.frank.computer/blog/2025/05/machine-utterance.html), as if there is no downside to any interaction and no risk or cost involved in anything we do.

But the greatest cost comes in how our tooling shapes us and "flattens our being" (as Heidegger writes). This is because truly feeling and experiencing pain and struggle is central to our humanity. We are both unique individuals and collectively unified through struggle. So a tool that intends us to never struggle is at fundamental odds with the pains that shape us.

And on the chair analogy: we can refuse to use chairs as they are designed (or even entirely). And we can use chairs for more than sitting. And we can design new chairs and non-chairs that do any sort of thing. We have the power and the responsibility to make our technologies shape humanity into something good and meaningful.

## So what do we do with AI?
<figure>
    <img src="https://www.frank.computer/images/isb.jpg" alt="illustration of Miyazaki drawing with cigarettes in his mouth in profile side with the caption &quot;If life's hassles disappeared, you'd want them back.&quot;"/>
    <figcaption>Credit: <a href="https://bsky.app/profile/samdoesarts.bsky.social/post/3lnzzxs2gw22o">Sam Yang, @samdoesarts.bsky.social</a></figcaption>
</figure>

Tools are immensely influential: they have the power to mold humanity, to include and exclude, to define what matters, and to literally shape the climate and environments we live in. "Tools" are radically powerful extensions of human will.

I want to argue that AI agents (as the corporate-controlled transformer and diffusion based models of our modern day) are largely bad to use, especially now, and in most all contexts. Their dangers are environmental, economic, and existential. As a "tool" they are far too destructive.

**On the environment**: modern AI agents have [accelerated climate change and come at an immense cost to our already precarious world](https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/?trk=feed_main-feed-card_feed-article-content). Continuing to use them is actively consenting to their continued destruction of our fresh water and energy resources. However, like many environmentally destructive industries, we could reign them in with policy and better, more efficient tech and infrastructure. Maybe someday the environmental damage will be under control and AI will be truly "sustainable."

**On the economics of AI**: Modern multi-billion parameter AI models are scaffolded on the largest theft in human history. Without prevention of and justice for the damage caused by current models, their use is highly fraught, ethically. Human beings have developed complex social forms of intelligence, as systems that enable us to give credit and to have provenance, two things that modern models are incapable of. And without recognition of the entire global economy of labor that enables current AI models, using them is active consent in their theft of all human art and knowledge.

**On our existence**: 
> [Tina He writes on our ontological crisis with modern AI](https://fakepixels.substack.com/p/ai-heidegger-and-evangelion),
> "**we are awakened to the danger precisely through contact with it**. The same algorithmic indifference that unsettles us may also jolt us into a higher vigilance, a refusal to hand over the entirety of our experience to optimization, market logic, or digital control. The very anxiety these systems produce is a clue: something vital, unquantifiable, and irreducibly human still resists."
> He continues,
> This isn’t about throwing away the tools, but about wrestling them into alignment with what we find sacred or essential.

So that is our charge. Our job now is the same as it always as been: to fight for our own humanity and for the health of the world, to not use tools uncritically, and to shape our tools before they shape us into flat nothingness.

Go and recognize those who taught and inspired you, "appreciate [your] predecessors and fellow-workers in the saltmines of literature," as Le Guin remarks, and go out and feel the good kind of pain that gives us shape and meaning; *become*.